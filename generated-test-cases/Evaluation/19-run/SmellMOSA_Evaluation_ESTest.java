/*
 * This file was automatically generated by EvoSuite
 * Thu Dec 17 08:18:12 GMT 2015
 */

package weka.classifiers;

import static org.junit.Assert.*;
import org.junit.Test;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.EvoSuiteLocalAddress;
import org.evosuite.runtime.testdata.EvoSuiteRemoteAddress;
import org.evosuite.runtime.testdata.EvoSuiteURL;
import org.junit.runner.RunWith;
import weka.classifiers.Classifier;
import weka.classifiers.CostMatrix;
import weka.classifiers.Evaluation;
import weka.classifiers.Sourcable;
import weka.classifiers.lazy.LWL;
import weka.classifiers.meta.AdaBoostM1;
import weka.classifiers.meta.AttributeSelectedClassifier;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.core.Instances;
import weka.core.TestInstances;
import weka.core.converters.TextDirectoryLoader;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true) 
public class Evaluation_ESTest extends Evaluation_ESTest_scaffolding {

  //Test case number: 0
  /*
   * 1 covered goal:
   * Goal 1. weka.classifiers.Evaluation.wekaStaticWrapper(Lweka/classifiers/Sourcable;Ljava/lang/String;)Ljava/lang/String;: root-Branch
   */

  @Test
  public void test00()  throws Throwable  {
      try {
        String string0 = Evaluation.wekaStaticWrapper((Sourcable) null, "");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  //Test case number: 1
  /*
   * 3 covered goals:
   * Goal 1. weka.classifiers.Evaluation.<init>(Lweka/core/Instances;Lweka/classifiers/CostMatrix;)V: I116 Branch 3 IFNULL L418 - false
   * Goal 2. weka.classifiers.Evaluation.<init>(Lweka/core/Instances;Lweka/classifiers/CostMatrix;)V: I124 Branch 4 IFNE L419 - true
   * Goal 3. weka.classifiers.Evaluation.<init>(Lweka/core/Instances;Lweka/classifiers/CostMatrix;)V: I155 Branch 5 IF_ICMPEQ L422 - false
   */

  @Test
  public void test01()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertNotNull(textDirectoryLoader0);
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01D);
      assertEquals("_Users_fabiopalomba_Documents_workspace_LunchEvosuite", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertNotNull(instances0);
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      assertEquals(1, costSensitiveClassifier0.MATRIX_ON_DEMAND);
      assertEquals(2, costSensitiveClassifier0.MATRIX_SUPPLIED);
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertNotNull(costSensitiveClassifier0);
      
      CostMatrix costMatrix0 = costSensitiveClassifier0.getCostMatrix();
      assertEquals(1, costSensitiveClassifier0.MATRIX_ON_DEMAND);
      assertEquals(2, costSensitiveClassifier0.MATRIX_SUPPLIED);
      assertEquals(1, costMatrix0.size());
      assertEquals(1, costMatrix0.numColumns());
      assertEquals(1, costMatrix0.numRows());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertNotNull(costMatrix0);
      
      Evaluation evaluation0 = null;
      try {
        evaluation0 = new Evaluation(instances0, costMatrix0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Cost matrix not compatible with data!
         //
      }
  }

  //Test case number: 2
  /*
   * 1 covered goal:
   * Goal 1. weka.classifiers.Evaluation.main([Ljava/lang/String;)V: I7 Branch 22 IFNE L801 - true
   */

  @Test
  public void test02()  throws Throwable  {
      String[] stringArray0 = new String[2];
      Evaluation.main(stringArray0);
  }

  //Test case number: 3
  /*
   * 1 covered goal:
   * Goal 1. weka.classifiers.Evaluation.handleCostOption(Ljava/lang/String;I)Lweka/classifiers/CostMatrix;: I12 Branch 166 IFEQ L1574 - false
   */

  @Test
  public void test03()  throws Throwable  {
      try {
        CostMatrix costMatrix0 = Evaluation.handleCostOption("Whether if the widths of the KDTree nde should be normalizd by the width of the universe or not. Where, width of the node is the rangeof the split attribute based on th instances in that node, and width of the universe is the range of the split attribute based on all the instances (default: alse).", 1856);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't open file null.
         //
      }
  }

  //Test case number: 4
  /*
   * 1 covered goal:
   * Goal 1. weka.classifiers.Evaluation.evaluateModel(Ljava/lang/String;[Ljava/lang/String;)Ljava/lang/String;: root-Branch
   */

  @Test
  public void test04()  throws Throwable  {
      String[] stringArray0 = new String[1];
      try {
        String string0 = Evaluation.evaluateModel("WhJther if the widths of the KDTree nde should be normalizd by the width of the universe or not. Where, width of the node is the rangeof the split attribute based on th instances in that node, and width of the universe is the range of the split attribute based on all the instances (default: alse).", stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class with name WhJther if the widths of the KDTree nde should be normalizd by the width of the universe or not. Where, width of the node is the rangeof the split attribute based on th instances in that node, and width of the universe is the range of the split attribute based on all the instances (default: alse)..
         //
      }
  }

  //Test case number: 5
  /*
   * 14 covered goals:
   * Goal 1. weka.classifiers.Evaluation.unclassified()D: root-Branch
   * Goal 2. weka.classifiers.Evaluation.toSummaryString()Ljava/lang/String;: root-Branch
   * Goal 3. weka.classifiers.Evaluation.areaUnderPRC(I)D: I7 Branch 12 IFNONNULL L521 - false
   * Goal 4. weka.classifiers.Evaluation.weightedAreaUnderPRC()D: I21 Branch 13 IF_ICMPGE L539 - true
   * Goal 5. weka.classifiers.Evaluation.weightedAreaUnderPRC()D: I21 Branch 13 IF_ICMPGE L539 - false
   * Goal 6. weka.classifiers.Evaluation.weightedAreaUnderPRC()D: I33 Branch 14 IF_ICMPGE L540 - true
   * Goal 7. weka.classifiers.Evaluation.weightedAreaUnderPRC()D: I33 Branch 14 IF_ICMPGE L540 - false
   * Goal 8. weka.classifiers.Evaluation.weightedAreaUnderPRC()D: I85 Branch 15 IF_ICMPGE L547 - true
   * Goal 9. weka.classifiers.Evaluation.weightedAreaUnderPRC()D: I85 Branch 15 IF_ICMPGE L547 - false
   * Goal 10. weka.classifiers.Evaluation.weightedAreaUnderPRC()D: I99 Branch 16 IFNE L549 - true
   * Goal 11. weka.classifiers.Evaluation.toSummaryString(Ljava/lang/String;Z)Ljava/lang/String;: I12 Branch 226 IFEQ L2512 - true
   * Goal 12. weka.classifiers.Evaluation.toSummaryString(Ljava/lang/String;Z)Ljava/lang/String;: I50 Branch 228 IFLE L2520 - true
   * Goal 13. weka.classifiers.Evaluation.toSummaryString(Ljava/lang/String;Z)Ljava/lang/String;: I625 Branch 237 IFEQ L2592 - true
   * Goal 14. weka.classifiers.Evaluation.toSummaryString(Ljava/lang/String;Z)Ljava/lang/String;: I689 Branch 238 IFLE L2599 - true
   */

  @Test
  public void test05()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), testInstances0.NO_CLASS);
      assertEquals((-1), testInstances0.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(-1, testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertNotNull(testInstances0);
      
      Instances instances0 = testInstances0.generate("getNumRuns");
      assertEquals((-2), testInstances0.NO_CLASS);
      assertEquals((-1), testInstances0.CLASS_IS_LAST);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(-1, testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01D);
      assertEquals(20, instances0.numInstances());
      assertNotNull(instances0);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), testInstances0.NO_CLASS);
      assertEquals((-1), testInstances0.CLASS_IS_LAST);
      assertEquals(0.0, evaluation0.totalCost(), 0.01D);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01D);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01D);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01D);
      assertEquals(0.0, evaluation0.unclassified(), 0.01D);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01D);
      assertEquals(0.0, evaluation0.numInstances(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01D);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedMatthewsCorrelation(), 0.01D);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01D);
      assertEquals(0.0, evaluation0.incorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01D);
      assertEquals(1.0, evaluation0.kappa(), 0.01D);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01D);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01D);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(-1, testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01D);
      assertEquals(20, instances0.numInstances());
      assertNotNull(evaluation0);
      
      double double0 = evaluation0.weightedAreaUnderPRC();
      assertEquals((-2), testInstances0.NO_CLASS);
      assertEquals((-1), testInstances0.CLASS_IS_LAST);
      assertEquals(0.0, evaluation0.totalCost(), 0.01D);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01D);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01D);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01D);
      assertEquals(0.0, evaluation0.unclassified(), 0.01D);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01D);
      assertEquals(0.0, evaluation0.numInstances(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01D);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedMatthewsCorrelation(), 0.01D);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01D);
      assertEquals(0.0, evaluation0.incorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01D);
      assertEquals(1.0, evaluation0.kappa(), 0.01D);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01D);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01D);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(-1, testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01D);
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, double0, 0.01D);
      
      String string0 = evaluation0.toSummaryString();
      assertEquals((-2), testInstances0.NO_CLASS);
      assertEquals((-1), testInstances0.CLASS_IS_LAST);
      assertEquals(0.0, evaluation0.totalCost(), 0.01D);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01D);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01D);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01D);
      assertEquals(0.0, evaluation0.unclassified(), 0.01D);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01D);
      assertEquals(0.0, evaluation0.numInstances(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01D);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedMatthewsCorrelation(), 0.01D);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01D);
      assertEquals(0.0, evaluation0.incorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01D);
      assertEquals(1.0, evaluation0.kappa(), 0.01D);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01D);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01D);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(-1, testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01D);
      assertEquals(20, instances0.numInstances());
      assertEquals("\nTotal Number of Instances                0     \n", string0);
      assertNotNull(string0);
  }

  //Test case number: 6
  /*
   * 2 covered goals:
   * Goal 1. weka.classifiers.Evaluation.handleCostOption(Ljava/lang/String;I)Lweka/classifiers/CostMatrix;: I6 Branch 165 IFNULL L1574 - false
   * Goal 2. weka.classifiers.Evaluation.handleCostOption(Ljava/lang/String;I)Lweka/classifiers/CostMatrix;: I12 Branch 166 IFEQ L1574 - true
   */

  @Test
  public void test06()  throws Throwable  {
      CostMatrix costMatrix0 = Evaluation.handleCostOption("", 547);
      assertNull(costMatrix0);
  }

  //Test case number: 7
  /*
   * 2 covered goals:
   * Goal 1. weka.classifiers.Evaluation.makeDistribution(D)[D: I13 Branch 360 IFEQ L3675 - true
   * Goal 2. weka.classifiers.Evaluation.makeDistribution(D)[D: I25 Branch 361 IFEQ L3678 - false
   */

  @Test
  public void test07()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertNotNull(textDirectoryLoader0);
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01D);
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("_Users_fabiopalomba_Documents_workspace_LunchEvosuite", instances0.relationName());
      assertNotNull(instances0);
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01D);
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("_Users_fabiopalomba_Documents_workspace_LunchEvosuite", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01D);
      assertEquals(0.0, evaluation0.unclassified(), 0.01D);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedMatthewsCorrelation(), 0.01D);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01D);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01D);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01D);
      assertEquals(0.0, evaluation0.numInstances(), 0.01D);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01D);
      assertEquals(0.0, evaluation0.incorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01D);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01D);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01D);
      assertEquals(1.0, evaluation0.kappa(), 0.01D);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01D);
      assertEquals(0.0, evaluation0.totalCost(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01D);
      assertNotNull(evaluation0);
      
      // Undeclared exception!
      try {
        double[] doubleArray0 = evaluation0.makeDistribution((-1114));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -1114
         //
      }
  }

  //Test case number: 8
  /*
   * 5 covered goals:
   * Goal 1. weka.classifiers.Evaluation.makeOptionString(Lweka/classifiers/Classifier;Z)Ljava/lang/String;: I380 Branch 351 IFEQ L3567 - false
   * Goal 2. weka.classifiers.Evaluation.makeOptionString(Lweka/classifiers/Classifier;Z)Ljava/lang/String;: I514 Branch 354 IFEQ L3599 - false
   * Goal 3. weka.classifiers.Evaluation.getGlobalInfo(Lweka/classifiers/Classifier;)Ljava/lang/String;: I42 Branch 355 IF_ICMPGE L3625 - false
   * Goal 4. weka.classifiers.Evaluation.getGlobalInfo(Lweka/classifiers/Classifier;)Ljava/lang/String;: I65 Branch 356 IFLE L3628 - true
   * Goal 5. weka.classifiers.Evaluation.getGlobalInfo(Lweka/classifiers/Classifier;)Ljava/lang/String;: I65 Branch 356 IFLE L3628 - false
   */

  @Test
  public void test08()  throws Throwable  {
      AttributeSelectedClassifier attributeSelectedClassifier0 = new AttributeSelectedClassifier();
      assertEquals("The base classifier to be used.", attributeSelectedClassifier0.classifierTipText());
      assertEquals("Dimensionality of training and test data is reduced by attribute selection before being passed on to a classifier.", attributeSelectedClassifier0.globalInfo());
      assertEquals("Set the search method. This search method is used during the attribute selection phase before the classifier is invoked.", attributeSelectedClassifier0.searchTipText());
      assertFalse(attributeSelectedClassifier0.getDebug());
      assertEquals("Set the attribute evaluator to use. This evaluator is used during the attribute selection phase before the classifier is invoked.", attributeSelectedClassifier0.evaluatorTipText());
      assertEquals(0.0, attributeSelectedClassifier0.measureNumAttributesSelected(), 0.01D);
      assertEquals("If set to true, classifier may output additional info to the console.", attributeSelectedClassifier0.debugTipText());
      assertEquals(0.0, attributeSelectedClassifier0.measureSelectionTime(), 0.01D);
      assertEquals(0.0, attributeSelectedClassifier0.measureTime(), 0.01D);
      assertEquals(1, attributeSelectedClassifier0.graphType());
      assertNotNull(attributeSelectedClassifier0);
      
      String string0 = Evaluation.makeOptionString(attributeSelectedClassifier0, true);
      assertEquals("The base classifier to be used.", attributeSelectedClassifier0.classifierTipText());
      assertEquals("Dimensionality of training and test data is reduced by attribute selection before being passed on to a classifier.", attributeSelectedClassifier0.globalInfo());
      assertEquals("Set the search method. This search method is used during the attribute selection phase before the classifier is invoked.", attributeSelectedClassifier0.searchTipText());
      assertFalse(attributeSelectedClassifier0.getDebug());
      assertEquals("Set the attribute evaluator to use. This evaluator is used during the attribute selection phase before the classifier is invoked.", attributeSelectedClassifier0.evaluatorTipText());
      assertEquals(0.0, attributeSelectedClassifier0.measureNumAttributesSelected(), 0.01D);
      assertEquals("If set to true, classifier may output additional info to the console.", attributeSelectedClassifier0.debugTipText());
      assertEquals(0.0, attributeSelectedClassifier0.measureSelectionTime(), 0.01D);
      assertEquals(0.0, attributeSelectedClassifier0.measureTime(), 0.01D);
      assertEquals(1, attributeSelectedClassifier0.graphType());
      assertEquals("\n\nGeneral options:\n\n-h or -help\n\tOutput help information.\n-synopsis or -info\n\tOutput synopsis for classifier (use in conjunction  with -h)\n-t <name of training file>\n\tSets training file.\n-T <name of test file>\n\tSets test file. If missing, a cross-validation will be performed\n\ton the training data.\n-c <class index>\n\tSets index of class attribute (default: last).\n-x <number of folds>\n\tSets number of folds for cross-validation (default: 10).\n-no-cv\n\tDo not perform any cross validation.\n-split-percentage <percentage>\n\tSets the percentage for the train/test set split, e.g., 66.\n-preserve-order\n\tPreserves the order in the percentage split.\n-s <random number seed>\n\tSets random number seed for cross-validation or percentage split\n\t(default: 1).\n-m <name of file with cost matrix>\n\tSets file with cost matrix.\n-l <name of input file>\n\tSets model input file. In case the filename ends with '.xml',\n\ta PMML file is loaded or, if that fails, options are loaded\n\tfrom the XML file.\n-d <name of output file>\n\tSets model output file. In case the filename ends with '.xml',\n\tonly the options are saved to the XML file, not the model.\n-v\n\tOutputs no statistics for training data.\n-o\n\tOutputs statistics only, not the classifier.\n-i\n\tOutputs detailed information-retrieval statistics for each class.\n-k\n\tOutputs information-theoretic statistics.\n-classifications \"weka.classifiers.evaluation.output.prediction.AbstractOutput + options\"\n\tUses the specified class for generating the classification output.\n\tE.g.: weka.classifiers.evaluation.output.prediction.PlainText\n-p range\n\tOutputs predictions for test instances (or the train instances if\n\tno test instances provided and -no-cv is used), along with the \n\tattributes in the specified range (and nothing else). \n\tUse '-p 0' if no attributes are desired.\n\tDeprecated: use \"-classifications ...\" instead.\n-distribution\n\tOutputs the distribution instead of only the prediction\n\tin conjunction with the '-p' option (only nominal classes).\n\tDeprecated: use \"-classifications ...\" instead.\n-r\n\tOnly outputs cumulative margin distribution.\n-g\n\tOnly outputs the graph representation of the classifier.\n-xml filename | xml-string\n\tRetrieves the options from the XML-data instead of the command line.\n-threshold-file <file>\n\tThe file to save the threshold data to.\n\tThe format is determined by the extensions, e.g., '.arff' for ARFF \n\tformat or '.csv' for CSV.\n-threshold-label <label>\n\tThe class label to determine the threshold data for\n\t(default is the first label)\n\nOptions specific to weka.classifiers.meta.AttributeSelectedClassifier:\n\n-E <attribute evaluator specification>\n\tFull class name of attribute evaluator, followed\n\tby its options.\n\teg: \"weka.attributeSelection.CfsSubsetEval -L\"\n\t(default weka.attributeSelection.CfsSubsetEval)\n-S <search method specification>\n\tFull class name of search method, followed\n\tby its options.\n\teg: \"weka.attributeSelection.BestFirst -D 1\"\n\t(default weka.attributeSelection.BestFirst)\n-D\n\tIf set, classifier is run in debug mode and\n\tmay output additional info to the console\n-W\n\tFull name of base classifier.\n\t(default: weka.classifiers.trees.J48)\n\nOptions specific to classifier weka.classifiers.trees.J48:\n\n-U\n\tUse unpruned tree.\n-O\n\tDo not collapse tree.\n-C <pruning confidence>\n\tSet confidence threshold for pruning.\n\t(default 0.25)\n-M <minimum number of instances>\n\tSet minimum number of instances per leaf.\n\t(default 2)\n-R\n\tUse reduced error pruning.\n-N <number of folds>\n\tSet number of folds for reduced error\n\tpruning. One fold is used as pruning set.\n\t(default 3)\n-B\n\tUse binary splits only.\n-S\n\tDon't perform subtree raising.\n-L\n\tDo not clean up after the tree has been built.\n-A\n\tLaplace smoothing for predicted probabilities.\n-J\n\tDo not use MDL correction for info gain on numeric attributes.\n-Q <seed>\n\tSeed for random data shuffling (default 1).\n\nSynopsis for weka.classifiers.meta.AttributeSelectedClassifier:\n\nDimensionality of training and test data is reduced by attribute selection before being passed on to a classifier.", string0);
      assertNotNull(string0);
  }

  //Test case number: 9
  /*
   * 1 covered goal:
   * Goal 1. weka.classifiers.Evaluation.handleCostOption(Ljava/lang/String;I)Lweka/classifiers/CostMatrix;: I6 Branch 165 IFNULL L1574 - true
   */

  @Test
  public void test09()  throws Throwable  {
      CostMatrix costMatrix0 = Evaluation.handleCostOption((String) null, (-4100));
      assertNull(costMatrix0);
  }

  //Test case number: 10
  /*
   * 1 covered goal:
   * Goal 1. weka.classifiers.Evaluation.rootMeanPriorSquaredError()D: I7 Branch 201 IFEQ L2266 - true
   */

  @Test
  public void test10()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertNotNull(textDirectoryLoader0);
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01D);
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_Users_fabiopalomba_Documents_workspace_LunchEvosuite", instances0.relationName());
      assertNotNull(instances0);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01D);
      assertEquals(0.0, evaluation0.totalCost(), 0.01D);
      assertEquals(1.0, evaluation0.kappa(), 0.01D);
      assertEquals(0.0, evaluation0.incorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01D);
      assertEquals(0.0, evaluation0.unclassified(), 0.01D);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01D);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01D);
      assertEquals(0.0, evaluation0.correct(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01D);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01D);
      assertEquals(0.0, evaluation0.numInstances(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01D);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01D);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedMatthewsCorrelation(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01D);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01D);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01D);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01D);
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_Users_fabiopalomba_Documents_workspace_LunchEvosuite", instances0.relationName());
      assertNotNull(evaluation0);
      
      double double0 = evaluation0.rootMeanPriorSquaredError();
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01D);
      assertEquals(0.0, evaluation0.totalCost(), 0.01D);
      assertEquals(1.0, evaluation0.kappa(), 0.01D);
      assertEquals(0.0, evaluation0.incorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01D);
      assertEquals(0.0, evaluation0.unclassified(), 0.01D);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01D);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01D);
      assertEquals(0.0, evaluation0.correct(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01D);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01D);
      assertEquals(0.0, evaluation0.numInstances(), 0.01D);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01D);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01D);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01D);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01D);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedMatthewsCorrelation(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01D);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01D);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01D);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01D);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01D);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01D);
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_Users_fabiopalomba_Documents_workspace_LunchEvosuite", instances0.relationName());
      assertEquals(Double.NaN, double0, 0.01D);
  }

  //Test case number: 11
  /*
   * 1 covered goal:
   * Goal 1. weka.classifiers.Evaluation.makeOptionString(Lweka/classifiers/Classifier;Z)Ljava/lang/String;: I436 Branch 352 IFEQ L3587 - true
   */

  @Test
  public void test11()  throws Throwable  {
      String string0 = Evaluation.makeOptionString((Classifier) null, false);
      assertEquals("\n\nGeneral options:\n\n-h or -help\n\tOutput help information.\n-synopsis or -info\n\tOutput synopsis for classifier (use in conjunction  with -h)\n-t <name of training file>\n\tSets training file.\n-T <name of test file>\n\tSets test file. If missing, a cross-validation will be performed\n\ton the training data.\n-c <class index>\n\tSets index of class attribute (default: last).\n-x <number of folds>\n\tSets number of folds for cross-validation (default: 10).\n-no-cv\n\tDo not perform any cross validation.\n-split-percentage <percentage>\n\tSets the percentage for the train/test set split, e.g., 66.\n-preserve-order\n\tPreserves the order in the percentage split.\n-s <random number seed>\n\tSets random number seed for cross-validation or percentage split\n\t(default: 1).\n-m <name of file with cost matrix>\n\tSets file with cost matrix.\n-l <name of input file>\n\tSets model input file. In case the filename ends with '.xml',\n\ta PMML file is loaded or, if that fails, options are loaded\n\tfrom the XML file.\n-d <name of output file>\n\tSets model output file. In case the filename ends with '.xml',\n\tonly the options are saved to the XML file, not the model.\n-v\n\tOutputs no statistics for training data.\n-o\n\tOutputs statistics only, not the classifier.\n-i\n\tOutputs detailed information-retrieval statistics for each class.\n-k\n\tOutputs information-theoretic statistics.\n-classifications \"weka.classifiers.evaluation.output.prediction.AbstractOutput + options\"\n\tUses the specified class for generating the classification output.\n\tE.g.: weka.classifiers.evaluation.output.prediction.PlainText\n-p range\n\tOutputs predictions for test instances (or the train instances if\n\tno test instances provided and -no-cv is used), along with the \n\tattributes in the specified range (and nothing else). \n\tUse '-p 0' if no attributes are desired.\n\tDeprecated: use \"-classifications ...\" instead.\n-distribution\n\tOutputs the distribution instead of only the prediction\n\tin conjunction with the '-p' option (only nominal classes).\n\tDeprecated: use \"-classifications ...\" instead.\n-r\n\tOnly outputs cumulative margin distribution.\n-xml filename | xml-string\n\tRetrieves the options from the XML-data instead of the command line.\n-threshold-file <file>\n\tThe file to save the threshold data to.\n\tThe format is determined by the extensions, e.g., '.arff' for ARFF \n\tformat or '.csv' for CSV.\n-threshold-label <label>\n\tThe class label to determine the threshold data for\n\t(default is the first label)\n", string0);
      assertNotNull(string0);
  }

  //Test case number: 12
  /*
   * 1 covered goal:
   * Goal 1. weka.classifiers.Evaluation.makeOptionString(Lweka/classifiers/Classifier;Z)Ljava/lang/String;: I360 Branch 350 IFEQ L3562 - true
   */

  @Test
  public void test12()  throws Throwable  {
      LWL lWL0 = new LWL();
      assertEquals(1, lWL0.EPANECHNIKOV);
      assertEquals(0, lWL0.LINEAR);
      assertEquals(2, lWL0.TRICUBE);
      assertEquals(3, lWL0.INVERSE);
      assertEquals(4, lWL0.GAUSS);
      assertEquals(5, lWL0.CONSTANT);
      assertEquals("The nearest neighbour search algorithm to use (Default: LinearNN).", lWL0.nearestNeighbourSearchAlgorithmTipText());
      assertFalse(lWL0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", lWL0.debugTipText());
      assertEquals("How many neighbours are used to determine the width of the weighting function (<= 0 means all neighbours).", lWL0.KNNTipText());
      assertEquals(0, lWL0.getWeightingKernel());
      assertEquals("The base classifier to be used.", lWL0.classifierTipText());
      assertEquals("Determines weighting function. [0 = Linear, 1 = Epnechnikov,2 = Tricube, 3 = Inverse, 4 = Gaussian and 5 = Constant. (default 0 = Linear)].", lWL0.weightingKernelTipText());
      assertEquals(-1, lWL0.getKNN());
      assertNotNull(lWL0);
      
      String string0 = Evaluation.makeOptionString(lWL0, false);
      assertEquals(1, lWL0.EPANECHNIKOV);
      assertEquals(0, lWL0.LINEAR);
      assertEquals(2, lWL0.TRICUBE);
      assertEquals(3, lWL0.INVERSE);
      assertEquals(4, lWL0.GAUSS);
      assertEquals(5, lWL0.CONSTANT);
      assertEquals("The nearest neighbour search algorithm to use (Default: LinearNN).", lWL0.nearestNeighbourSearchAlgorithmTipText());
      assertFalse(lWL0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", lWL0.debugTipText());
      assertEquals("How many neighbours are used to determine the width of the weighting function (<= 0 means all neighbours).", lWL0.KNNTipText());
      assertEquals(0, lWL0.getWeightingKernel());
      assertEquals("The base classifier to be used.", lWL0.classifierTipText());
      assertEquals("Determines weighting function. [0 = Linear, 1 = Epnechnikov,2 = Tricube, 3 = Inverse, 4 = Gaussian and 5 = Constant. (default 0 = Linear)].", lWL0.weightingKernelTipText());
      assertEquals(-1, lWL0.getKNN());
      assertEquals("\n\nGeneral options:\n\n-h or -help\n\tOutput help information.\n-synopsis or -info\n\tOutput synopsis for classifier (use in conjunction  with -h)\n-t <name of training file>\n\tSets training file.\n-T <name of test file>\n\tSets test file. If missing, a cross-validation will be performed\n\ton the training data.\n-c <class index>\n\tSets index of class attribute (default: last).\n-x <number of folds>\n\tSets number of folds for cross-validation (default: 10).\n-no-cv\n\tDo not perform any cross validation.\n-split-percentage <percentage>\n\tSets the percentage for the train/test set split, e.g., 66.\n-preserve-order\n\tPreserves the order in the percentage split.\n-s <random number seed>\n\tSets random number seed for cross-validation or percentage split\n\t(default: 1).\n-m <name of file with cost matrix>\n\tSets file with cost matrix.\n-l <name of input file>\n\tSets model input file. In case the filename ends with '.xml',\n\ta PMML file is loaded or, if that fails, options are loaded\n\tfrom the XML file.\n-d <name of output file>\n\tSets model output file. In case the filename ends with '.xml',\n\tonly the options are saved to the XML file, not the model.\n-v\n\tOutputs no statistics for training data.\n-o\n\tOutputs statistics only, not the classifier.\n-i\n\tOutputs detailed information-retrieval statistics for each class.\n-k\n\tOutputs information-theoretic statistics.\n-classifications \"weka.classifiers.evaluation.output.prediction.AbstractOutput + options\"\n\tUses the specified class for generating the classification output.\n\tE.g.: weka.classifiers.evaluation.output.prediction.PlainText\n-p range\n\tOutputs predictions for test instances (or the train instances if\n\tno test instances provided and -no-cv is used), along with the \n\tattributes in the specified range (and nothing else). \n\tUse '-p 0' if no attributes are desired.\n\tDeprecated: use \"-classifications ...\" instead.\n-distribution\n\tOutputs the distribution instead of only the prediction\n\tin conjunction with the '-p' option (only nominal classes).\n\tDeprecated: use \"-classifications ...\" instead.\n-r\n\tOnly outputs cumulative margin distribution.\n-xml filename | xml-string\n\tRetrieves the options from the XML-data instead of the command line.\n-threshold-file <file>\n\tThe file to save the threshold data to.\n\tThe format is determined by the extensions, e.g., '.arff' for ARFF \n\tformat or '.csv' for CSV.\n-threshold-label <label>\n\tThe class label to determine the threshold data for\n\t(default is the first label)\n\nOptions specific to weka.classifiers.lazy.LWL:\n\n-A\n\tThe nearest neighbour search algorithm to use (default: weka.core.neighboursearch.LinearNNSearch).\n\n-K <number of neighbours>\n\tSet the number of neighbours used to set the kernel bandwidth.\n\t(default all)\n-U <number of weighting method>\n\tSet the weighting kernel shape to use. 0=Linear, 1=Epanechnikov,\n\t2=Tricube, 3=Inverse, 4=Gaussian.\n\t(default 0 = Linear)\n-D\n\tIf set, classifier is run in debug mode and\n\tmay output additional info to the console\n-W\n\tFull name of base classifier.\n\t(default: weka.classifiers.trees.DecisionStump)\n\nOptions specific to classifier weka.classifiers.trees.DecisionStump:\n\n-D\n\tIf set, classifier is run in debug mode and\n\tmay output additional info to the console\n", string0);
      assertNotNull(string0);
  }

  //Test case number: 13
  /*
   * 17 covered goals:
   * Goal 1. weka.classifiers.Evaluation.evaluateModel(Lweka/classifiers/Classifier;[Ljava/lang/String;)Ljava/lang/String;: I144 Branch 23 IFNE L963 - false
   * Goal 2. weka.classifiers.Evaluation.evaluateModel(Lweka/classifiers/Classifier;[Ljava/lang/String;)Ljava/lang/String;: I151 Branch 24 IFEQ L963 - true
   * Goal 3. weka.classifiers.Evaluation.evaluateModel(Lweka/classifiers/Classifier;[Ljava/lang/String;)Ljava/lang/String;: I221 Branch 27 IFGT L976 - true
   * Goal 4. weka.classifiers.Evaluation.evaluateModel(Lweka/classifiers/Classifier;[Ljava/lang/String;)Ljava/lang/String;: I247 Branch 28 IF_ICMPGE L981 - true
   * Goal 5. weka.classifiers.Evaluation.evaluateModel(Lweka/classifiers/Classifier;[Ljava/lang/String;)Ljava/lang/String;: I247 Branch 28 IF_ICMPGE L981 - false
   * Goal 6. weka.classifiers.Evaluation.evaluateModel(Lweka/classifiers/Classifier;[Ljava/lang/String;)Ljava/lang/String;: I277 Branch 29 IFLE L986 - true
   * Goal 7. weka.classifiers.Evaluation.evaluateModel(Lweka/classifiers/Classifier;[Ljava/lang/String;)Ljava/lang/String;: I394 Branch 32 IFEQ L1017 - true
   * Goal 8. weka.classifiers.Evaluation.evaluateModel(Lweka/classifiers/Classifier;[Ljava/lang/String;)Ljava/lang/String;: I471 Branch 35 IFEQ L1030 - true
   * Goal 9. weka.classifiers.Evaluation.evaluateModel(Lweka/classifiers/Classifier;[Ljava/lang/String;)Ljava/lang/String;: I490 Branch 36 IFEQ L1034 - true
   * Goal 10. weka.classifiers.Evaluation.evaluateModel(Lweka/classifiers/Classifier;[Ljava/lang/String;)Ljava/lang/String;: I503 Branch 37 IFNE L1037 - false
   * Goal 11. weka.classifiers.Evaluation.evaluateModel(Lweka/classifiers/Classifier;[Ljava/lang/String;)Ljava/lang/String;: I511 Branch 38 IFNE L1038 - false
   * Goal 12. weka.classifiers.Evaluation.makeOptionString(Lweka/classifiers/Classifier;Z)Ljava/lang/String;: I360 Branch 350 IFEQ L3562 - false
   * Goal 13. weka.classifiers.Evaluation.makeOptionString(Lweka/classifiers/Classifier;Z)Ljava/lang/String;: I380 Branch 351 IFEQ L3567 - true
   * Goal 14. weka.classifiers.Evaluation.makeOptionString(Lweka/classifiers/Classifier;Z)Ljava/lang/String;: I436 Branch 352 IFEQ L3587 - false
   * Goal 15. weka.classifiers.Evaluation.makeOptionString(Lweka/classifiers/Classifier;Z)Ljava/lang/String;: I467 Branch 353 IFEQ L3591 - true
   * Goal 16. weka.classifiers.Evaluation.makeOptionString(Lweka/classifiers/Classifier;Z)Ljava/lang/String;: I467 Branch 353 IFEQ L3591 - false
   * Goal 17. weka.classifiers.Evaluation.makeOptionString(Lweka/classifiers/Classifier;Z)Ljava/lang/String;: I514 Branch 354 IFEQ L3599 - true
   */

  @Test
  public void test13()  throws Throwable  {
      AdaBoostM1 adaBoostM1_0 = new AdaBoostM1();
      assertEquals("The base classifier to be used.", adaBoostM1_0.classifierTipText());
      assertFalse(adaBoostM1_0.getDebug());
      assertEquals("Whether resampling is used instead of reweighting.", adaBoostM1_0.useResamplingTipText());
      assertEquals("The number of iterations to be performed.", adaBoostM1_0.numIterationsTipText());
      assertEquals("Weight threshold for weight pruning.", adaBoostM1_0.weightThresholdTipText());
      assertEquals(100, adaBoostM1_0.getWeightThreshold());
      assertEquals(10, adaBoostM1_0.getNumIterations());
      assertEquals(1, adaBoostM1_0.getSeed());
      assertFalse(adaBoostM1_0.getUseResampling());
      assertEquals("If set to true, classifier may output additional info to the console.", adaBoostM1_0.debugTipText());
      assertEquals("The random number seed to be used.", adaBoostM1_0.seedTipText());
      assertNotNull(adaBoostM1_0);
      
      String[] stringArray0 = new String[1];
      stringArray0[0] = "WhJther if the widths of the KDTree nde should be normalizd by the width of the universe or not. Where, width of the node is the rangeof the split attribute based on th instances in that node, and width of the universe is the range of the split attribute based on all the instances (default: alse).";
      try {
        String string0 = Evaluation.evaluateModel((Classifier) adaBoostM1_0, stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // 
         // Weka exception: No training file and no object input file given.
         // 
         // General options:
         // 
         // -h or -help
         // \tOutput help information.
         // -synopsis or -info
         // \tOutput synopsis for classifier (use in conjunction  with -h)
         // -t <name of training file>
         // \tSets training file.
         // -T <name of test file>
         // \tSets test file. If missing, a cross-validation will be performed
         // \ton the training data.
         // -c <class index>
         // \tSets index of class attribute (default: last).
         // -x <number of folds>
         // \tSets number of folds for cross-validation (default: 10).
         // -no-cv
         // \tDo not perform any cross validation.
         // -split-percentage <percentage>
         // \tSets the percentage for the train/test set split, e.g., 66.
         // -preserve-order
         // \tPreserves the order in the percentage split.
         // -s <random number seed>
         // \tSets random number seed for cross-validation or percentage split
         // \t(default: 1).
         // -m <name of file with cost matrix>
         // \tSets file with cost matrix.
         // -l <name of input file>
         // \tSets model input file. In case the filename ends with '.xml',
         // \ta PMML file is loaded or, if that fails, options are loaded
         // \tfrom the XML file.
         // -d <name of output file>
         // \tSets model output file. In case the filename ends with '.xml',
         // \tonly the options are saved to the XML file, not the model.
         // -v
         // \tOutputs no statistics for training data.
         // -o
         // \tOutputs statistics only, not the classifier.
         // -i
         // \tOutputs detailed information-retrieval statistics for each class.
         // -k
         // \tOutputs information-theoretic statistics.
         // -classifications \"weka.classifiers.evaluation.output.prediction.AbstractOutput + options\"
         // \tUses the specified class for generating the classification output.
         // \tE.g.: weka.classifiers.evaluation.output.prediction.PlainText
         // -p range
         // \tOutputs predictions for test instances (or the train instances if
         // \tno test instances provided and -no-cv is used), along with the 
         // \tattributes in the specified range (and nothing else). 
         // \tUse '-p 0' if no attributes are desired.
         // \tDeprecated: use \"-classifications ...\" instead.
         // -distribution
         // \tOutputs the distribution instead of only the prediction
         // \tin conjunction with the '-p' option (only nominal classes).
         // \tDeprecated: use \"-classifications ...\" instead.
         // -r
         // \tOnly outputs cumulative margin distribution.
         // -z <class name>
         // \tOnly outputs the source representation of the classifier,
         // \tgiving it the supplied name.
         // -xml filename | xml-string
         // \tRetrieves the options from the XML-data instead of the command line.
         // -threshold-file <file>
         // \tThe file to save the threshold data to.
         // \tThe format is determined by the extensions, e.g., '.arff' for ARFF 
         // \tformat or '.csv' for CSV.
         // -threshold-label <label>
         // \tThe class label to determine the threshold data for
         // \t(default is the first label)
         // 
         // Options specific to weka.classifiers.meta.AdaBoostM1:
         // 
         // -P <num>
         // \tPercentage of weight mass to base training on.
         // \t(default 100, reduce to around 90 speed up)
         // -Q
         // \tUse resampling for boosting.
         // -S <num>
         // \tRandom number seed.
         // \t(default 1)
         // -I <num>
         // \tNumber of iterations.
         // \t(default 10)
         // -D
         // \tIf set, classifier is run in debug mode and
         // \tmay output additional info to the console
         // -W
         // \tFull name of base classifier.
         // \t(default: weka.classifiers.trees.DecisionStump)
         // 
         // Options specific to classifier weka.classifiers.trees.DecisionStump:
         // 
         // -D
         // \tIf set, classifier is run in debug mode and
         // \tmay output additional info to the console
         //
      }
  }
}
